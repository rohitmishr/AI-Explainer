# ğŸ§  AI Code Explainer

A FastAPI-powered backend that uses local LLMs via [Ollama](https://ollama.com) to intelligently explain your code. Upload any `.py`, `.js`, `.ts`, `.html`, `.json`, `.txt`, or even a `.zip` file of your project â€” and get an instant explanation with audio narration using Google Text-to-Speech (`gTTS`).

---

## ğŸš€ Features

- ğŸ“‚ Upload single files or `.zip` folders
- ğŸ” Get detailed explanations of code functionality
- ğŸ’¡ Includes optimization and improvement suggestions
- ğŸ”Š Auto-generates MP3 voice narration of explanation
- âš¡ Built with FastAPI + Ollama + gTTS
- ğŸ§  Local LLM-powered: No API keys required!

---

## ğŸ“¦ Installation & Setup

### 1. Clone the Repository

```
git clone https://github.com/rohitmishr/ai-code-explainer.git
cd ai-code-explainer

```
### 2. Set Up a Python Virtual Environment

```
python -m venv venv
source venv/bin/activate     # For Windows: venv\Scripts\activate
```
### 3. Install Python Dependencies

- pip install -r requirements.txt

- requirements.txt:

```
fastapi
uvicorn
requests
python-multipart
gTTS
```

### 4. Install Ollama (for LLM support)

- Visit: https://ollama.com/download

- After installation:
- ollama pull codellama:7b-instruct
- ollama serve
- âš ï¸ Keep this terminal running. Ollama serves the LLM on http://localhost:11434.

![alt text](ollama_installation.png)

### 5. Run the FastAPI Server
```
In a new terminal:


python3 run.py
Visit the interactive Swagger UI:


http://localhost:8000/docs

```
## ğŸ—‚ Project Structure
```
.
â”œâ”€â”€ main.py                 # FastAPI API routes
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ app.py              # FastAPI app setup & CORS
â”‚   â””â”€â”€ explain_utils.py    # Core logic for file processing + LLM + gTTS
â”œâ”€â”€ static/audio/           # Auto-generated MP3 explanations
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
### ğŸ§ª Usage

- â–¶ Upload a file
- Navigate to /docs

- Use the /upload endpoint

- Upload a .py, .js, or .zip file

```
Youâ€™ll receive:

{
  "file": "loginuser.py",
  "explanation": {
    "text": "This module handles login and auth...",
    "audio_url": "/static/audio/loginuser_py.mp3"
  }
}

```
![alt text](swagger_response.png)

## â–¶ Listen to the explanation

```
Go to:
http://localhost:8000/static/audio/loginuser_py.mp3
(Replace loginuser_py.mp3 with your actual filename.)
```
![alt text](audio_access.png)


## ğŸ” How It Works

- User uploads a file or .zip

- File content is extracted and read

- Sent to local Ollama LLM (codellama:7b-instruct) with a custom prompt

- AI returns a plain-English explanation + suggestions

- gTTS generates an .mp3 from the explanation

- FastAPI serves both text and audio response

## ğŸ›  Technologies Used
```
FastAPI â€“ high-performance API framework

Ollama + CodeLlama â€“ self-hosted large language model

gTTS â€“ Google Text-to-Speech

Python â€“ main backend language

Uvicorn â€“ ASGI server
```
## ğŸ“Œ Future Enhancements

- Frontend using Streamlit or React

- PDF/Markdown exports of explanations

- GitHub repo link support

- Syntax-highlighted explanation view

## ğŸ‘¨â€ğŸ’» Author

### Rohit Kumar Mishra

- ğŸ“§ Email: rohityahoo593@gmail.com

- ğŸŒ Portfolio [https://sites.google.com/view/rohitkumarmishra/home]

- ğŸ’» GitHub [https://github.com/rohitmishr/]

- ğŸ’¼ LinkedIn [https://www.linkedin.com/in/rohit-kumar-mishra-16728a1a1/]

### ğŸ“„ License

N/A â€” use it, improve it, and share it!


---






